<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Theory Seminar: Kate Donahue | Penn CS Theory Group</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="This week&rsquo;s theory seminar speaker is Kate Donahue of Cornell University. As usual, the talk will take place in Room 401B, 3401 Walnut Street on Friday 12-1 PM. Talk and speaker details are included below
Title: Stability, Optimality, and Fairness in Federated Learning
Abstract: Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error or fairness."><meta name=generator content="Hugo 0.120.4"><meta name=robots content="index, follow"><link rel=stylesheet href=/ananke/css/main.min.20b8a2d86dc4fda0308929d3b2e26e2bd0dd4405359d6ffed7a13f21487dfbc2.css><link rel="shortcut icon" href=/images/favicon.png type=image/x-icon><meta property="og:title" content="Theory Seminar: Kate Donahue"><meta property="og:description" content="This week&rsquo;s theory seminar speaker is Kate Donahue of Cornell University. As usual, the talk will take place in Room 401B, 3401 Walnut Street on Friday 12-1 PM. Talk and speaker details are included below
Title: Stability, Optimality, and Fairness in Federated Learning
Abstract: Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error or fairness."><meta property="og:type" content="article"><meta property="og:url" content="https://theory.cis.upenn.edu/post/kated/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-09-08T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-08T00:00:00+00:00"><meta itemprop=name content="Theory Seminar: Kate Donahue"><meta itemprop=description content="This week&rsquo;s theory seminar speaker is Kate Donahue of Cornell University. As usual, the talk will take place in Room 401B, 3401 Walnut Street on Friday 12-1 PM. Talk and speaker details are included below
Title: Stability, Optimality, and Fairness in Federated Learning
Abstract: Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error or fairness."><meta itemprop=datePublished content="2023-09-08T00:00:00+00:00"><meta itemprop=dateModified content="2023-09-08T00:00:00+00:00"><meta itemprop=wordCount content="394"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Theory Seminar: Kate Donahue"><meta name=twitter:description content="This week&rsquo;s theory seminar speaker is Kate Donahue of Cornell University. As usual, the talk will take place in Room 401B, 3401 Walnut Street on Friday 12-1 PM. Talk and speaker details are included below
Title: Stability, Optimality, and Fairness in Federated Learning
Abstract: Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error or fairness."></head><body class="ma0 avenir bg-near-white production"><header class="cover bg-top" style=background-image:url(https://theory.cis.upenn.edu/images/welcome.jpg)><div class=bg-black-60><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Penn CS Theory Group</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/people/ title="People page">People</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/seminar/ title="Theory Seminar Schedule page">Theory Seminar Schedule</a></li></ul><div class=ananke-socials></div></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><div class="f2 f1-l fw2 white-90 mb0 lh-title">Theory Seminar: Kate Donahue</div></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">EVENTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Theory Seminar: Kate Donahue</h1><time class="f6 mv4 dib tracked" datetime=2023-09-08T00:00:00Z>September 8, 2023</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>This week&rsquo;s theory seminar speaker is Kate Donahue of Cornell University. As usual, the talk will take place in Room 401B, 3401 Walnut Street on Friday 12-1 PM. Talk and speaker details are included below</p><p><strong>Title:</strong> Stability, Optimality, and Fairness in Federated Learning</p><p><strong>Abstract:</strong> Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error or fairness. In this talk, I describe three papers analyzing federated learning through the lens of cooperative game theory, all joint with Jon Kleinberg (<a href=https://arxiv.org/abs/2010.00753>https://arxiv.org/abs/2010.00753</a>, <a href=https://arxiv.org/abs/2106.09580>https://arxiv.org/abs/2106.09580</a>, <a href=https://arxiv.org/abs/2112.00818>https://arxiv.org/abs/2112.00818</a>)</p><p>In the first paper, we discuss fairness in federated learning, which relates to how error rates differ between federating agents. In this work, we consider two notions of fairness: egalitarian fairness (which aims to bound how dissimilar error rates can be) and proportional fairness (which aims to reward players for contributing more data). For egalitarian fairness, we obtain a tight multiplicative bound on how widely error rates can diverge between agents federating together. For proportional fairness, we show that sub-proportional error (relative to the number of data points contributed) is guaranteed for any individually rational federating coalition. The second paper explores optimality in federated learning with respect to an objective of minimizing the average error rate among federating agents. In this work, we provide and prove the correctness of an efficient algorithm to calculate an optimal (error minimizing) arrangement of players. This paper builds on our prior work on stability in federated learning, and allows us to give the first constant-factor bound on the performance gap between stability and optimality, proving that the total error of the worst stable solution can be no higher than 9 times the total error of an optimal solution (Price of Anarchy bound of 9).</p><p><strong>Bio:</strong> Kate Donahue is a fifth year computer science PhD candidate at Cornell advised by Jon Kleinberg. She works on algorithmic problems relating to the societal impact of AI such as fairness, human/AI collaboration and game-theoretic models of federated learning. Her work has been supported by an NSF fellowship and recognized by a FAccT Best Paper award. During her PhD, she has interned at Microsoft Research, Amazon, and Google.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><div><div class=ananke-socials></div></div></div></footer></body></html>